---
title: "Intero_2023_preprocess_beh"
author: "Helio"
date: "2023-02-18"
output: html_document
---


# this might be needed for temporal analisys
write_csv(dta_gp_all_fix_sacc, 'dta_gp_all_fix_sacc.csv')




Set-up: where I load libraries and create objects for later use (such as color schemes etc).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# store date
current_date<- Sys.Date()

# libraries
require(tidyverse)
require(data.table)
require(readr)
```


Load behavioural data

Behavioral data

```{r}
# colnames(X309_2019_Dec_11_1807_01)
library(data.table) 
library(purrr)

# setwd("~/OneDrive - Nexus365/InteroStudy2020/analysis/DataAnalysisJanuary2020/DataAnalysisJan2020/IAPSBehav/346_355")


tmp_files <- list.files(pattern = "01.csv")

dta_beh <-  rbindlist(sapply(tmp_files, read.csv, simplify = FALSE),
                use.names = TRUE, idcol = "filename",fill=TRUE)

colnames(dta_beh)

# we have new columns here
dta_beh$happiness_3.response
dta_beh$mouse_3.clicked_text #categorical

dta_beh1<- dta_beh%>%
select("filename", "condition", "stimIAPS","stimDescription", "ValenceMean","ArousalMean","trigger",
                                     "trialsPract.thisTrialN","trialIAPS.thisTrialN", "self_valence_4.response","self_valence_2.response","Self_intensity_2.response","Self_intensity_3.response", "self_valence_4.rt", "self_valence_2.rt", "Self_intensity_2.rt", "Self_intensity_3.rt",108,110,112,113,116,118,122,"mouse_3.clicked_text")
# 
# read_plus_beh <- function(flnm, select = c("condition", "stimIAPS","stimDescription", "ValenceMean","ArousalMean","trigger",
#                                      "trialsPract.thisTrialN","trialIAPS.thisTrialN", "self_valence_4.response","self_valence_2.response","Self_intensity_2.response","Self_intensity_3.response", "self_valence_4.rt", "self_valence_2.rt", "Self_intensity_2.rt", "Self_intensity_3.rt")) {
#   read.csv(flnm) %>% 
#     mutate(filename = flnm)
# }


colnames(dta_beh1)

dta_beh1$emotiion_cat_resp<- dta_beh1$mouse_3.clicked_text

dta_beh1<- dta_beh1%>%
  subset(!is.na(stimIAPS))

# create ssid
dta_beh1$ssid<- substr(dta_beh1$filename, 1,3)

# for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))

View(dta_beh1)


# crate vaklence rating
dta_beh1$valence<- if_else(is.na(dta_beh1$self_valence_4.response) == FALSE, dta_beh1$self_valence_4.response,
                          if_else(is.na(dta_beh1$self_valence_2.response) == FALSE, dta_beh1$self_valence_2.response, NULL))

# create aropusal rating
dta_beh1$Self_intensity_3.response<- as.double(dta_beh1$Self_intensity_3.response)                      

dta_beh1$arousal<- if_else(is.na(dta_beh1$Self_intensity_2.response) == FALSE, as.numeric(dta_beh1$Self_intensity_2.response),
                          if_else(is.na(dta_beh1$Self_intensity_3.response) == FALSE,
                                  as.numeric(dta_beh1$Self_intensity_3.response), NULL))

dta_beh1$arousal

# reaction times
dta_beh1$valence_rt<- if_else(is.na(dta_beh1$self_valence_4.rt) == FALSE, dta_beh1$self_valence_4.rt,
                          if_else(is.na(dta_beh1$self_valence_2.rt) == FALSE, dta_beh1$self_valence_2.rt, NULL))
                          
dta_beh1$arousal_rt<- if_else(is.na(dta_beh1$Self_intensity_2.rt) == FALSE, dta_beh1$Self_intensity_2.rt,
                          if_else(is.na(dta_beh1$Self_intensity_3.rt) == FALSE, dta_beh1$Self_intensity_3.rt, NULL))

# trial number
dta_beh1$trialsPract.thisTrialN<- dta_beh1$trialsPract.thisTrialN - 6

dta_beh1$trialIAPS.thisTrialN<-dta_beh1$trialIAPS.thisTrialN +1 
dta_beh1$tNo<- if_else(is.na(dta_beh1$Self_intensity_2.response) == FALSE, dta_beh1$trialsPract.thisTrialN, dta_beh1$trialIAPS.thisTrialN)
unique(dta_beh1$tNo)

dta_beh1<- subset(dta_beh1, is.na(dta_beh1$tNo) == FALSE)

# sort
dta_beh1<- dta_beh1%>%
  arrange(ssid, tNo)

ggplot(dta_beh1, aes(tNo, valence, colour = ssid))+
  geom_point()+
  geom_line()


ggplot(dta_beh1, aes(x = valence, y = ValenceMean))+
  geom_point()+
  geom_smooth(method = lm, se = T)

ggplot(dta_beh1, aes(x = arousal, y = ArousalMean))+
  geom_point()+
  geom_smooth(method = lm, se = T)

unique(dta_beh1$trigger)

dta_beh1$triggeracq <- dta_beh1$trigger
unique(dta_beh1$ssid)
colnames(dta_beh1)
# dta_beh1<- select(dta_beh1, c(2:7, 18:23))
# colnames(dta_beh1_301_309)

dta_beh1$trigger<-NULL
# dta_beh1_301_309$triggeracq<- NULL


dta_beh1$condition[dta_beh1$condition == "Example Stimuli"]<- "Practice"

unique(dta_beh1$condition)

dta_beh1
```


questionnaires


gorilla codes


STAI:: 5nzr
AQ:7uqw
STAIS: 8rfo
Demog: 8zto
BVAQ: 83b1
BPQ: bbc4
DASS: chif
IQ: esh8
IAS: jvi8
TAS:pdlt
demog_meantal health: v2gn

AQ_50

quick check that Lucys scoring are correct

```{r}
# Traditional scoring

setwd("~/OneDrive - Nexus365/InteroStudy2020/analysis/DataAnalysisJanuary2020/DataAnalysisJan2020/selfreport")

library(readr)

db_quest_checkAQ<- read_csv("data_exp_11458-v8_questionnaire-7uqw.csv")
View(db_quest_checkAQ)

library(tidyverse)
colnames(db_quest_checkAQ)

db_quest_checkAQ<- db_quest_checkAQ%>%
  select(c(16,31:130))
  
db_quest_checkAQ_1<- db_quest_checkAQ%>%
select(seq(1, 101, 2))



# create a prefix for AQ items
# https://it.unt.edu/sites/default/files/paste_jds_jun2013.pdf - some nice tips here
prefix<- "AQ_"

AQ_counter<- seq(1,50)


aq_labels<-paste(prefix, AQ_counter, sep = "")
# generate odd numbers to match the columns we wnt to keep
names<- c("completion_code", aq_labels)

# rename dataset
names(db_quest_checkAQ_1)<- names

db_quest_checkAQ_2<- db_quest_checkAQ_1 %>%
#   mutate_at(c('TAS_4', 'TAS_5', 'TAS_10', 'TAS_18', 'TAS_19'), 
#             funs(recode(., "1=5; 2=4; 3=3; 4=2; 5 =1")))%>%
# #    2, 4, 5, 6, 7, 9, 12, 13, 16, 18,
# # 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46
  mutate_at(c("AQ_2", "AQ_4", "AQ_5", "AQ_6", "AQ_7", "AQ_9", "AQ_12", "AQ_13", "AQ_16", "AQ_18",
                 "AQ_19","AQ_20", "AQ_21", "AQ_22", "AQ_23", "AQ_26", "AQ_33", "AQ_35", "AQ_39", "AQ_41",
                 "AQ_42",
                 "AQ_43", "AQ_45", "AQ_46"), 
            funs(ifelse(. <= 2, 1, 0)))%>%
            # funs(recode(., "1=1; 2=1; 3=0; 4=0")))%>%
   mutate_at(c("AQ_1", "AQ_3", "AQ_8", "AQ_10", "AQ_11", "AQ_14", "AQ_15", "AQ_17", "AQ_24", "AQ_25",
                 "AQ_27","AQ_28", "AQ_29", "AQ_30", "AQ_31", "AQ_32", "AQ_34", "AQ_36", "AQ_37", "AQ_38",
                 "AQ_40",
                 "AQ_44", "AQ_47", "AQ_48", "AQ_49", "AQ_50"), 
             funs(ifelse(. > 2, 1, 0)))
             # funs(recode(., "1=0; 2=0; 3=1; 4=1")))



db_quest_checkAQ_2%>%
  # mutate(DIF = TAS_1 + TAS_3 + TAS_6 + TAS_7 + TAS_9 + TAS_13+ TAS_14)%>%
  # mutate(EOT = TAS_8+TAS_15+TAS_16+TAS_20+TAS_5+TAS_10+TAS_18+TAS_19)%>%
  # mutate(DDF = TAS_2+TAS_11+TAS_12+TAS_17+TAS_4)%>%
  mutate(SS = AQ_1+ AQ_11+ AQ_13 + AQ_15+ AQ_22 + AQ_36 + AQ_44 + AQ_45 + AQ_47 + AQ_48)%>%
  mutate(AS = AQ_2+ AQ_4 + AQ_10+AQ_16+AQ_25+AQ_32+AQ_34+AQ_37+AQ_43+AQ_46)%>%
  mutate(ATD = AQ_5+AQ_6+AQ_9+AQ_12+AQ_19+ AQ_23+AQ_28+AQ_29+AQ_30+AQ_49)%>%
  mutate(COM = AQ_7+AQ_17+AQ_18+AQ_26+AQ_27+AQ_31+AQ_33+AQ_35+AQ_38+AQ_39)%>%
  mutate(IMAG = AQ_3+AQ_8+AQ_14+AQ_20+AQ_21+ AQ_24+AQ_40+AQ_41+AQ_42+AQ_50)%>%
  # mutate(TAS_Total = DIF + DDF + EOT)%>%
  mutate(AQ_Total = SS + AS +ATD + COM + IMAG)%>%
  select(c(completion_code, AQ_Total))
  ggplot(aes(TAS_Total, AQ_Total))+
  geom_point()+
  facet_grid(~Dataset)
  
```

this confirms that Lucy scoring is correct
also checked a few examples of TAS seem correct. but should note one inconsistency in the first participant (300)

AQ_50

hcqzar		mobile	Samsung SM-G950F	Android 9 are the same person = 357
```{r}

# read_selfrep1 <- function(flnm) {
#     read_csv(flnm) %>%
#         mutate(filename = flnm)
# }

library(readxl)
dta_AQ_2022_23 <- aq_50_data_exp_60619_v2_questionnaire_7uqw <- read_excel("aq 50 data_exp_60619-v2_questionnaire-7uqw.xlsx")
View(dta_AQ_2022_23)

dta_AQ_2022_23<- dta_AQ_2022_23%>%janitor::clean_names()

unique(dta_AQ_2022_23$question_key)

dta_AQ_2022_23$question_key<- str_replace(dta_AQ_2022_23$question_key, "Q0", "AQ_")
?str_replace
unique(dta_AQ_2022_23$question_key)
unique(str_replace(dta_AQ_2022_23$question_key, "Q", "AQ_"))


dta_AQ_2022_23$question_key<- str_replace(dta_AQ_2022_23$question_key, "Q", "AQ_")
unique(dta_AQ_2022_23$question_key)
dta_AQ_2022_23$question_key<- str_replace(dta_AQ_2022_23$question_key, "AA", "A")
unique(dta_AQ_2022_23$question_key)


dta_AQ_2022_23$question_key<- str_replace(dta_AQ_2022_23$question_key, "__", "_")
unique(dta_AQ_2022_23$question_key)

dta_AQ_2022_23$participant_completion_code
# unique(db_AQ$`Participant Completion Code`)
# unique(db_AQ$`Participant Public ID`)


library(tidyverse)


dta_AQ_2022_23$completion_code<- dta_AQ_2022_23$participant_completion_code

dta_AQ_2022_23

colnames(dta_AQ_2022_23)

dta_AQ_2022_23<- dta_AQ_2022_23%>%
  select(c(12,13,32:34)) %>%
  subset(grepl("quantised",question_key)) %>%
  mutate(question_key = str_remove_all(question_key, "-quantised"))

colnames(dta_AQ_2022_23)
dta_AQ_2022_23_spread<-dta_AQ_2022_23%>%
  spread(question_key,response)


```
  

# create a prefix for AQ items
# https://it.unt.edu/sites/default/files/paste_jds_jun2013.pdf - some nice tips here
prefix<- "AQ_"

```{r, score AQ}

paste0("AQ_", seq(1:50))

# reorder
dta_AQ_2022_23_spread<-dta_AQ_2022_23_spread%>%
  select(c(colnames(dta_AQ_2022_23_spread)[1:3],paste0("AQ_", seq(1:50))))
# this line selects the first 3 column names and a vector with ordered AQ1 to 50

dta_AQ_2022_23_spread

colnames(dta_AQ_2022_23_spread)
dta_AQ_2022_23_spread1

# transofmr AQ ratings to numberic
dta_AQ_2022_23_spread<- dta_AQ_2022_23_spread%>%
  mutate_at(c(paste0("AQ_", seq(1:50))), as.numeric) # this line is a a struck to select only aq columns

dta_AQ_2022_23_spread1<-dta_AQ_2022_23_spread%>%

  mutate_at(c("AQ_2", "AQ_4", "AQ_5", "AQ_6", "AQ_7", "AQ_9", "AQ_12", "AQ_13", "AQ_16", "AQ_18",
                 "AQ_19","AQ_20", "AQ_21", "AQ_22", "AQ_23", "AQ_26", "AQ_33", "AQ_35", "AQ_39", "AQ_41",
                 "AQ_42",
                 "AQ_43", "AQ_45", "AQ_46"), 
            funs(ifelse(. <= 2, 1, 0)))%>%
            # funs(recode(., "1=1; 2=1; 3=0; 4=0")))%>%
   mutate_at(c("AQ_1", "AQ_3", "AQ_8", "AQ_10", "AQ_11", "AQ_14", "AQ_15", "AQ_17", "AQ_24", "AQ_25",
                 "AQ_27","AQ_28", "AQ_29", "AQ_30", "AQ_31", "AQ_32", "AQ_34", "AQ_36", "AQ_37", "AQ_38",
                 "AQ_40",
                 "AQ_44", "AQ_47", "AQ_48", "AQ_49", "AQ_50"), 
             funs(ifelse(. > 2, 1, 0)))
             # funs(recode(., "1=0; 2=0; 3=1; 4=1")))

dta_AQ_2022_23_spread1
colnames(dta_AQ_2022_23_spread1)
dta_AQ_2022_23_spread1_scored<- dta_AQ_2022_23_spread1%>%
  # mutate(DIF = TAS_1 + TAS_3 + TAS_6 + TAS_7 + TAS_9 + TAS_13+ TAS_14)%>%
  # mutate(EOT = TAS_8+TAS_15+TAS_16+TAS_20+TAS_5+TAS_10+TAS_18+TAS_19)%>%
  # mutate(DDF = TAS_2+TAS_11+TAS_12+TAS_17+TAS_4)%>%
  mutate(SS = AQ_1+ AQ_11+ AQ_13 + AQ_15+ AQ_22 + AQ_36 + AQ_44 + AQ_45 + AQ_47 + AQ_48)%>%
  mutate(AS = AQ_2+ AQ_4 + AQ_10+AQ_16+AQ_25+AQ_32+AQ_34+AQ_37+AQ_43+AQ_46)%>%
  mutate(ATD = AQ_5+AQ_6+AQ_9+AQ_12+AQ_19+ AQ_23+AQ_28+AQ_29+AQ_30+AQ_49)%>%
  mutate(COM = AQ_7+AQ_17+AQ_18+AQ_26+AQ_27+AQ_31+AQ_33+AQ_35+AQ_38+AQ_39)%>%
  mutate(IMAG = AQ_3+AQ_8+AQ_14+AQ_20+AQ_21+ AQ_24+AQ_40+AQ_41+AQ_42+AQ_50)%>%
  # mutate(TAS_Total = DIF + DDF + EOT)%>%
  mutate(AQ = SS + AS +ATD + COM + IMAG)%>%
  select(c(completion_code,participant_public_id,participant_private_id, AQ,SS, ATD, COM, IMAG))
  

db_AQ4

```

TAS

```{r, TAS Alexithymia}

library(readxl)
dta_TAS_2022_23 <- read_excel("tas 20 data_exp_60619-v2_questionnaire-682g.xlsx")
View(dta_TAS_2022_23)

colnames(dta_TAS_2022_23)

dta_TAS_2022_23_scored<- dta_TAS_2022_23%>%
  janitor::clean_names()%>%
  select(c(12,13,32:33))%>%
  subset(!grepl("QUESTIONNAIRE|TAS",question_key))%>%
  subset(!is.na(question_key))%>%
  spread(question_key,response)
```


merge with AQ to check if patterns are as expected

```{r}

left_join(dta_AQ_2022_23_spread1_scored,
dta_TAS_2022_23_scored)%>%
  ggplot(aes(AQ,TotalAlexScore))+
  geom_point()

```

checks out

now demographics


```{r}
library(readxl)
dta_demog_20222_23 <- read_excel("age, eligibility, gender data_exp_60619-v2_questionnaire-8zto.xlsx")
View(dta_demog_20222_23)


colnames(dta_demog_20222_23)
dta_demog_20222_23_pt1<- dta_demog_20222_23%>%
  janitor::clean_names()%>%
  select(c(12,13,32:33))%>%
  subset(!grepl("QUESTIONNAIRE|quantised",question_key))%>%
  subset(!is.na(question_key))%>%
  spread(question_key,response)

# 
library(readxl)
dta_demog_20222_23_v2gn <- read_excel("diagnosis data_exp_60619-v2_questionnaire-v2gn.xlsx")
View(dta_demog_20222_23_v2gn)
colnames(dta_demog_20222_23_v2gn)
dta_demog_20222_23_v2gn

 dta_demog_20222_23_v2gn_wide<-dta_demog_20222_23_v2gn%>%
  janitor::clean_names()%>%
  select(c(12,13,32:33))%>%
  subset(!grepl("QUESTIONNAIRE|quantised",question_key))%>%
  subset(!is.na(question_key))%>%
  spread(question_key,response)%>%
  select(-clinical_diagnosis)
 
 
dta_demog_20222_23_pt1bind<- left_join(dta_demog_20222_23_pt1, dta_demog_20222_23_v2gn_wide)

dta_demog_20222_23_pt1bind
```
to do merge mental health and IQ
IQ: esh8

```{r}
library(readxl)
dta_IQ_2022_23 <- read_excel("not sure what these are/data_exp_60619-v2_task-esh8.xlsx")

View(dta_IQ_2022_23)



dta_IQ_2022_23$Response

dta_IQ_2022_23<- dta_IQ_2022_23%>%
  janitor::clean_names()
dta_IQ_2022_23<- subset(dta_IQ_2022_23, !is.na(response))



colnames(dta_IQ_2022_23)

dta_IQ_2022_23_score<- dta_IQ_2022_23%>%
  select( c(12,13, 36,44,46,55,16))%>%
  group_by(participant_private_id, participant_public_id,participant_completion_code)%>%
  summarise_if(is.numeric, sum, na.rm = TRUE)

dta_IQ_2022_23_score$Matrix_Total<- dta_IQ_2022_23_score$correct
# dta_IQ_2022_23_score$IQ_matrix_sum<- NULL
dta_IQ_2022_23_score$correct<-NULL
dta_IQ_2022_23_score$completion_code<- dta_IQ_2022_23_score$participant_completion_code

dta_IQ_2022_23_score$participant_completion_code<-NULL

dta_demog_20222_23_pt1bind<-left_join(dta_demog_20222_23_pt1bind, dta_IQ_2022_23_score)

colnames(dta_beh1)
dta_quests<- left_join(dta_demog_20222_23_pt1bind,dta_AQ_2022_23_spread1_scored)
dta_quests<-left_join(dta_quests,dta_TAS_2022_23_scored)
dta_AQ_2022_23_spread1_scored

colnames(dta_quests)
# merge with behaviour

# load logbook

dta_logbook <- read_excel("Interoception Study Logbook (2).xlsx")
View(dta_logbook)
dta_logbook<- dta_logbook%>%
  janitor::clean_names()

dta_logbook$completion_code

colnames(dta_logbook)

dta_ssid_code<- select(dta_logbook, c(1:3))
dta_ssid_code$completion_code

dta_ssid_code$participant_no

dta_ssid_code$ssid<- substr(dta_ssid_code$participant_no,1,3)
dta_ssid_code$ssid
temp_ssid_to_keep<- unique(dta_beh1$ssid)
unique(dta_ssid_code$ssid)

table(dta_ssid_code$ssid)

dta_ssid_code<- dta_ssid_code%>%
  subset(participant_no !="624 (FALSE START)")

dta_beh1<-left_join(dta_beh1,dta_ssid_code)

dta_bhv_quest<- left_join(dta_beh1,dta_AQ_2022_23_spread1_scored)
```
dta_bhv_quest = dataset with behavioura data and questionnaires/iq, demographics